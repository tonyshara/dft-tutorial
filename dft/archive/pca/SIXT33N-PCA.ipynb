{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIXT33N Project\n",
    "## Phase 5: PCA/Classificiation - Voice Commands\n",
    "\n",
    "### EE 16B: Designing Information Devices and Systems II, Spring 2018\n",
    "\n",
    "Written by Nathaniel Mailoa and Emily Naviasky (2016)\n",
    "\n",
    "nmailoa@berkeley.edu &emsp; enaviasky@berkeley.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name 1**:\n",
    "\n",
    "**Login**: ee16b-\n",
    "\n",
    "\n",
    "**Name 2**:\n",
    "\n",
    "**Login**: ee16b-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Introduction](#intro)\n",
    "* [Part 1: Data Collection](#part1)\n",
    "* [Part 2: Principal Component Analysis](#part2)\n",
    "* [Part 3: Classification](#part3)\n",
    "* [Part 4: Launchpad Implementation](#part4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "SIXT33N is an obedient little robot that will follow the directions that you tell it. There are four moves that SIXT33N can make: move straight, move straight slowly, turn right, and turn left. However, SIXT33N does not speak human languages, and some words, like \"left\" and \"right\", sound very similar (a strong single syllable), while other words are easy to distinguish. Your job in this phase is to find four command words that are easy for SIXT33N to tell apart (consider syllables and intonation).\n",
    "\n",
    "For phase 3, you will develop the PCA classifier that allows SIXT33N to tell the difference between the four commands. You will examine several different test words, and determine which ones will be easiest to sort by PCA.\n",
    "\n",
    "Once you have some sample data collected, you will perform PCA and look at how well it separates the sample data. Then, once you have a set of four words that you like, you will use k-means to automatically classify them. When you (and your GSI) are satisfied with the classifier's accuracy, you will port the classifier into the Launchpad code in Energia.\n",
    "\n",
    "<b>\n",
    "The goals of this phase are as follows:\n",
    "- Generate envelope and utilize threshold to get snippets\n",
    "- PCA + Classifier (4 commands)\n",
    "- Check accuracy\n",
    "- PCA projection on Launchpad\n",
    "</b>\n",
    "\n",
    "The checkpoints (marked **<span style=\"color:green\">green</span>** in the Notebook) are:\n",
    "- Checkpoint 1: First pass through PCA with sample data; GSI feedback\n",
    "- Checkpoint 2: Classification target met in Python\n",
    "\n",
    "Note that all of this is considered a single graded lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part1'></a>\n",
    "## <span style=\"color:blue\">Part 1: Data Collection</span>\n",
    "\n",
    "### Materials\n",
    "- Microphone front-end circuit\n",
    "- Launchpad + USB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When humans distinguish words, they listen for temporal and frequency differences to determine what is being said. However, SIXT33N does not have the memory or the processing power to distinguish words nearly as well as our human brains, so we will have to choose much simpler features for SIXT33N to look at (syllables, intonation, magnitude).\n",
    "\n",
    "When you think of speech signals, you might notice that the shape of the speech wave is a very distinctive part of each word. Taking just the shape of the magnitude of a signal is called enveloping, exemplified in the image below. So, we want to do some filtering to retrieve the envelope of the audio signal. We train the PCA off of just this envelope and build a classifier to classify new data points.\n",
    "\n",
    "<center>\n",
    "<img width=\"400px\" src=\"images/proj-envelope.png\">\n",
    "</center>\n",
    "\n",
    "<b>Keeping in mind that the words that look most different have different shapes (or different amplitudes varied over time), brainstorm four or five words that you think will sort well. Consider syllables, intonation, and length of the word.</b>\n",
    "\n",
    "**<span style=\"color:red\">What words are you going to try? Why?</span>** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, upload the sketch <b>`collect-data-envelope.ino`</b> to your Launchpad. This sketch gathers ADC samples every 0.35ms, and streams the data back to the PC.\n",
    "\n",
    "Next, hook up your front end circuit.<b> Make sure to disconnect the 5V jumper from the Launchpad</b>, or you will power the Launchpad from the power supply as well as from the USB cord. \n",
    "\n",
    "<b>Tip: To not lose the jumper, only connect the jumper on one pin so it stays on your launchpad without powering it and creating a connection. Remember to put it back at the end of the lab. The pictures below shows the original configuration of the 5V jumper and modified one for this lab</b> \n",
    "\n",
    "<center>\n",
    "<img width=\"400px\" src=\"images/msp-jumpers.png\">\n",
    "<img width=\"400px\" src=\"images/5vjumper.jpg\">\n",
    "</center>\n",
    "\n",
    "\n",
    "Do not power up your circuit for now, we will connect the appropriate Launchpad pins to your circuit first:\n",
    "- P6.0 to the microphone front end circuit output\n",
    "- 3.3V pin to the 3.3V power rail of the breadboard (in particular to supply the buffer op-amp)\n",
    "- 5V pin to the 5V row where your MicBoard V_DD is located\n",
    "- GND pin to the ground rail of the breadboard\n",
    "\n",
    "You can keep your MSP plugged via USB as long as <b>YOUR JUMPER IS DISCONNECTED</b>\n",
    "\n",
    "Next, use the bench power supply to provide 5V to the circuit. **<span color='red'>DO NOT FORGET TO SET THE CURRENT LIMIT.</span>** <b>Before you start recording, use the oscilloscope to probe the output of the microphone circuit. Make sure the waveform averages to 1.65V (halfway between 0V and 3.3V) and the amplitude is large enough.</b> Make a noise at the microphone; you should see the signal change to reflect the sound you just made. If you are close enough or loud enough, you should be able to get the peak-to-peak amplitude of your signal all the way up to 3.3V.\n",
    "\n",
    "<center>\n",
    "<img width=\"400px\" src=\"images/proj-waveform.png\">\n",
    "</center>\n",
    "\n",
    "\"Good\" Audio data has a high signal to noise ratio. Recording words while far away from the microphone may cause your intended word to blend in with background noise. However \"oversaturation\" of the audio signal (speaking too loudly and/or too closely into the mic) will distort the signal (Why?). You can use the oscilloscope on the front-end output to test for over/under saturation.\n",
    "\n",
    "You should already have <b>`collect-data-envelope.ino`</b> uploaded to your Launchpad. This sketch will turn on the red Launchpad LED to show that it is recording. The Launchpad will record 2 seconds of audio at a time, sampled every 0.35ms. \n",
    "\n",
    "<b>The red LED on the launch pad is like a recording room. When the red light goes on, the Launchpad is recording. Say the word you want to record before the red LED turns off.</b>\n",
    "\n",
    "To make your life easier, pronounce the words consistently. Try <b>five or six words</b> that you think will classify well. The Launchpad will apply an enveloping function (discussed later) which reduces the data from several thousand samples to 172 samples. \n",
    "\n",
    "The Launchpad has limited memory and will delete the enveloped data as soon as the red light flashes again. To record the data permanently, the Launchpad must be connected to a PC by the USB, allowing it to transfer its data\n",
    "\n",
    "To transfer the data in the PC, make sure the Launchpad is connected, then run:\n",
    "\n",
    "<b>`python collect-data-envelope.py log.csv`</b>\n",
    "\n",
    "Now, each time the light flashes and a sample is collected by the Launchpad, it will be written into to some file called `log.csv`. You might want to probe the output and watch the scope while you collect. After you collect, a few test words, check the `log.csv` and make sure that it looks like a sound wave and is not just full of zeros. It might help to plot the data on excel to make sure.\n",
    "\n",
    "Now the Launchpad will send the audio data to the PC in addition to collecting and enveloping it. The python script will write into an excel file called `log.csv`, one enveloped sample per row. After collection, make sure the tables are not filled with zeroes.\n",
    "\n",
    "\n",
    "<b>Collect around 15 good samples for each of your four to five words</b>, and be sure to save them to different .csv files with descriptive names. You will collect more once you settle on the four words that sort well enough.\n",
    "\n",
    "Just in case: To write to different .csv files, just change `log.csv` to `TheWordYouWant.csv` in <b>`python collect-data-envelope.py log.csv`</b>.\n",
    "\n",
    "#### For your Consideration:\n",
    "\n",
    "Once you have your four or more words collected, you can move onto the PCA classification below. You may realize in the next section that one or two of your words are not sorting quite as well as you would like. Don't be afraid to come back to this section and try collecting different words based on what you have learned makes a word sortable. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\"> Summary TO DO for part 1: </span>** \n",
    "- **<span style=\"color:red\">Keep MSP powered via USB</span>**\n",
    "- **<span style=\"color:red\">Disconnect 5V jumper from Launchpad</span>**\n",
    "- **<span style=\"color:red\">Connect P6.0 to the microphone front end circuit output</span>**\n",
    "- **<span style=\"color:red\">Connect 3.3V pin of the launchpad to the 3V power rail of the breadboard (in particular to supply the buffer op-amp) </span>**\n",
    "- **<span style=\"color:red\">Connect the 5V pin of the launchpad to V_DD of micboard and supply 5V from the power supply (remember to set the current limit!)</span>**\n",
    "- **<span style=\"color:red\">Connect the GND pin of the launchpad to the ground rail of the breadboard</span>**\n",
    "- **<span style=\"color:red\">Upload `collect-data-envelope.ino` onto launchpad</span>**\n",
    "- **<span style=\"color:red\">Run `python collect-data-envelope.py log.csv` on your PC to collect data into `log.csv`</span>**\n",
    "- **<span style=\"color:red\">Record 15 samples for each of your 4 to 5 words (Saying your word each time the red light flashes)</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part2'></a>\n",
    "## <span style=\"color:blue\">Part 2: Principal Component Analysis</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use the recorded data for PCA, we must first process the data. It is not necessary for you to understand the enveloping function well enough to implement it (since we have already done it for you), but just in case you are curious the enveloping function is described in the following pseudocode:\n",
    "\n",
    "<code><b>Enveloping function</b>\n",
    "Divide the whole signal to a block of 16 samples\n",
    "For each chunk:\n",
    "    Find the mean of the chunk\n",
    "    Subtract each sample by the mean\n",
    "    Find the sum of the absolute value of each sample\n",
    "</code>\n",
    "\n",
    "What you really need to know, however, is what the enveloped signal looks like for each word. Spend a little time looking at the data you just collected in the python plots below.\n",
    "\n",
    "First, load the recorded data from the csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import scipy.cluster\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        r = csv.reader(csvfile, delimiter=' ')\n",
    "        for row in r:\n",
    "            data.append([float(i) for i in row[0].split(',')])\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv\n",
    "# YOUR CODE HERE\n",
    "word1_raw = read_csv(\".csv\")\n",
    "word2_raw = read_csv(\".csv\")\n",
    "word3_raw = read_csv(\".csv\")\n",
    "word4_raw = read_csv(\".csv\")\n",
    "\n",
    "# Take the same number of readings for all words to be fair\n",
    "num_samples = min(np.shape(word1_raw)[0], np.shape(word2_raw)[0], np.shape(word3_raw)[0], np.shape(word4_raw)[0])\n",
    "word1_raw = word1_raw[:num_samples,:]\n",
    "word2_raw = word2_raw[:num_samples,:]\n",
    "word3_raw = word3_raw[:num_samples,:]\n",
    "word4_raw = word4_raw[:num_samples,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot your data and get a feel for how it looks enveloped.\n",
    "\n",
    "**<span style=\"color:red\">Important: It's okay if the data isn't aligned. The code in the next part will automatically align the data.</span>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all word1 samples\n",
    "plt.plot(word1_raw.T)\n",
    "plt.show()\n",
    "plt.plot(word2_raw.T)\n",
    "plt.show()\n",
    "plt.plot(word3_raw.T)\n",
    "plt.show()\n",
    "plt.plot(word4_raw.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the speech is only a small part of the 2 second window, and each sample starts at different times. PCA is not good at interpreting delay, so we need to somehow start in the same place each time and capture a smaller segment of the 2 second sample where the speech is present. To do this, we will use a thresholding algorithm.\n",
    "\n",
    "First, we define a **`threshold`** relative to the maximum value of the data. We say that any signal that crosses the threshold is the start of a speech command. In order to not lose the first couple samples of the speech command, we say that the command starts **`pre_length`** samples before the threshold is crossed. We then take a window of the data that is **`length`** long, and try to capture the entire sound of the command in that window.\n",
    "\n",
    "<b>Play around with the parameters `length`, `pre_length` and `threshold`</b> in the cells below to find appropriate values corresponding to your voice and chosen commands. You should see the results and how much of your command you captured in the plots generated below. When you are satisfied, note down the values of `length`, `pre_length` and `threshold` - <b>you will need to add them to the Launchpad sketch later.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_snippets(data, length, pre_length, thres):\n",
    "    data_out = np.zeros((np.shape(data)[0], length))\n",
    "    \n",
    "    for rnum, row in enumerate(data):\n",
    "        # Find the threshold\n",
    "        row_thres = thres*np.max(row)\n",
    "\n",
    "        # Figure out when interesting snippet starts\n",
    "        block = pre_length\n",
    "        while (row[block] < row_thres):\n",
    "            block = block + 1\n",
    "        block = min(block, 172 - length)\n",
    "        data_out[rnum,:] = row[block-pre_length:block-pre_length+length]\n",
    "        \n",
    "        # Normalization\n",
    "        data_out[rnum,:] = data_out[rnum,:] / np.sum(data_out[rnum,:])\n",
    "        \n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = # Default: 40        # Adjust this\n",
    "pre_length = # Default: 5     # Adjust this\n",
    "threshold = # Default:  0.5    # Adjust this\n",
    "\n",
    "word1_processed = get_snippets(word1_raw, length, pre_length, threshold)\n",
    "plt.plot(word1_processed.T)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "word2_processed = get_snippets(word2_raw, length, pre_length, threshold)\n",
    "plt.plot(word2_processed.T)\n",
    "plt.show()\n",
    "word3_processed = get_snippets(word3_raw, length, pre_length, threshold)\n",
    "plt.plot(word3_processed.T)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "word4_processed = get_snippets(word4_raw, length, pre_length, threshold)\n",
    "plt.plot(word4_processed.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see a mostly organized set of samples for each word. Can you tell the which word is which just by the envelope? Can you tell them apart? If you can't tell the words apart, then PCA will have a difficult time as well.\n",
    "\n",
    "Now that we have our data in a nice format, we can build the PCA input matrix from that data. The function <b>`np.vstack`</b> might be helpful here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE #\n",
    "processed_A = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code below to perform SVD on your matrix A (is there a function in one of our libraries that can help?), plot the sigma values, and project on to the principal components. First zero-mean your data as `demeaned_A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zero-mean the matrix A. Note down the mean for the Launchpad code\n",
    "# YOUR CODE HERE #\n",
    "mean_vec = \n",
    "demeaned_A = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the SVD of matrix demeaned_A\n",
    "# YOUR CODE HERE #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot out the sigma values (Hint: Use plt.stem for a stem plot)\n",
    "# YOUR CODE HERE #\n",
    "plt.xlim([-1,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at your sigma values. They should show you very clearly how many principal components you need.\n",
    "\n",
    "**<span style=\"color:red\">How many principal components do you need? Given that you are sorting 4 words, what is the the number you expect to need?</span>** \n",
    "\n",
    "There is no correct answer here. We can pick as many principal components onto which we project our data to get the \"best\" separation (most variance), but at some point, the cost-benefit isn't worth selecting an extra basis vector. For example, in our project, we are loading these basis vectors onto the [MSP430 Launchpad](http://www.ti.com/tool/MSP-EXP430F5529LP), and we can only store 2-3 principal components before we run into memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the principal component(s)\n",
    "# YOUR CODE HERE #\n",
    "new_basis =         # This should be the basis containing your principal components\n",
    "plt.plot(new_basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now project the data in the matrix A onto the new basis and plot it. Do you see clustering? Do you think you can separate the data easily? If not, you might need to try new words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Project the data onto the new basis\n",
    "# YOUR CODE HERE #\n",
    "proj = \n",
    "\n",
    "plt.scatter(proj[0:num_samples,0], proj[0:num_samples,1], c=['blue'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples:num_samples*2,0], proj[num_samples:num_samples*2,1], c=['red'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples*2:num_samples*3,0], proj[num_samples*2:num_samples*3,1], c=['green'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples*3:num_samples*4,0], proj[num_samples*3:num_samples*4,1], c=['orange'], edgecolor='none')\n",
    "plt.legend(['word1', 'word2', 'word3', 'word4'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color:green\">**First pass through PCA with sample data.** Show your GSI the result of the projection and talk about how you might be able to improve the result.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your data might look noisy, and might not classify perfectly. That is completely okay, we are just looking for good enough. Like many AI applications, this is noisy data that we are classifying so some error in classification is okay. The important part is if you think that you can see some clustering. \n",
    "\n",
    "Once you think you have decent clustering, you can move on to getting your code to automate classification and you will make up for some of the error there, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Summary TO DO for Part 2</span>** \n",
    "- **<span style=\"color:red\">Load words from CSV</span>** \n",
    "- **<span style=\"color:red\">Plot the your enveloped words and make sure they are distinguishable. Else re-record words</span>** \n",
    "- **<span style=\"color:red\">Play around with `length`, `prelength` and `threshold` until you settle on desirable values</span>** \n",
    "- **<span style=\"color:red\">Construct the A matrix from data</span>** \n",
    "- **<span style=\"color:red\">Further process the A matrix (hint hint: De-mean it)</span>** \n",
    "- **<span style=\"color:red\">Take the SVD of A and plot the sigma values - how many principal components do you need ? </span>** \n",
    "- **<span style=\"color:red\">Project data from A matrix onto selected number of principal components (should you use U or V)</span>** \n",
    "- **<span style=\"color:red\">Plot the projections</span>** \n",
    "- **<span style=\"color:red\">Make sure that the projected data clusters properly. If clustering is not apparent. re-collect data. </span>** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part3'></a>\n",
    "## <span style=\"color:blue\">Part 3:  K-Means Classification</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the plot above, we will define a way of classifying the different words. Fill in the skeleton code below to classify a vector in your new basis. \n",
    "\n",
    "Use a few of speech samples you collected at the beginning and test your classification on them. <b>Don't forget to do the same processing on these samples that you trained with</b> (i.e. do zero-mean by subtracting the mean of the original matrix A).\n",
    "\n",
    "You will use k-means to classify, just as you did in the your BMI homework question. If you need a refresher, you can check the python documentation for the function **`scipy.cluster.vq.kmeans`** <a href=\"http://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.vq.kmeans.html#scipy.cluster.vq.kmeans\">here</a>.\n",
    "\n",
    "You need to be a little careful when creating the classifying algorithm since we do not want SIXT33N to pick up random sounds and treat them as one of the commands. To do this, pick a reasonably tight boundary for your classification.\n",
    "\n",
    "**<span style=\"color:red\"> Note: The order in which the centroids is returned is nondeterministic - save the centroid values and matching word somewhere safe. When you rerun find_centroids you may need to go back and reassign your matching word!!!!</span>** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_centroids(clustered_data, num_of_clusters):\n",
    "    \"\"\" Use scipy.cluster.vq.kmeans to determine centroids of clusters\n",
    "    Parameters:\n",
    "        clustered_data: the data already projected onto the new basis\n",
    "        num_of_clusters: the expected number of clusters in the data\n",
    "    Returns: \n",
    "        The centroids of the clusters\n",
    "    Note: You do NOT need to call the whiten function\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the centroids of each cluster\n",
    "# YOUR CODE HERE\n",
    "centroids = \n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output ordering of k-means is non-deterministic,\n",
    "# so we have one cell (above) that runs it, and another (this one)\n",
    "# that orders the result\n",
    "\n",
    "# YOUR CODE HERE\n",
    "centroid1 = centroids[]\n",
    "centroid2 = centroids[]\n",
    "centroid3 = centroids[]\n",
    "centroid4 = centroids[]\n",
    "centroid_list = np.vstack([centroid1, centroid2, centroid3, centroid4])\n",
    "\n",
    "print('The first centroid is at: ' + str(centroid1))\n",
    "print('The second centroid is at: ' + str(centroid2))\n",
    "print('The third centroid is at: ' + str(centroid3))\n",
    "print('The fourth centroid is at: ' + str(centroid4))\n",
    "\n",
    "plt.scatter(proj[0:num_samples,0], proj[0:num_samples,1], c=['blue'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples:num_samples*2,0], proj[num_samples:num_samples*2,1], c=['red'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples*2:num_samples*3,0], proj[num_samples*2:num_samples*3,1], c=['green'], edgecolor='none')\n",
    "plt.scatter(proj[num_samples*3:num_samples*4,0], proj[num_samples*3:num_samples*4,1], c=['orange'], edgecolor='none')\n",
    "\n",
    "plt.scatter(centroid_list[:,0], centroid_list[:,1], c=['blue', 'red', 'green', 'orange'], marker='*', s=300)\n",
    "plt.legend(['word1', 'word2', 'word3', 'word4'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(data_point):\n",
    "    \"\"\"\n",
    "    Classifies a new reading vector into a word.\n",
    "    Inputs:\n",
    "        data_point: new data point vector (before projection)\n",
    "    Output:\n",
    "        Word number\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out the classification function\n",
    "print(classify(processed_A[0,:])) # Modify to use other vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our goal is 80% accuracy for each word.** Write code to apply the `classify` function to each sample and compute the accuracy for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to classify the whole A matrix\n",
    "correct_counts = np.zeros(4)\n",
    "\n",
    "for (row_num, data) in enumerate(processed_A):\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "for i in range(len(correct_counts)):\n",
    "    print(\"Percent correct of word {} = {}\".format(i, correct_counts[i]/num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Summary TO DO for Part 3:</span>** \n",
    "- **<span style=\"color:red\">Fill in function to find the centroids of the clustered data - K Means will output them in a nondeterministic order</span>** \n",
    "- **<span style=\"color:red\">Fill in function to classify the words - make sure you apply the same preprocessing to the words (demeaning)</span>** \n",
    "- **<span style=\"color:red\">Make sure you have an 80% classification rate for each word. Else you need to re-collect data</span>** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
